{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batches.meta data_batch_2 data_batch_4 readme.html\r\n",
      "data_batch_1 data_batch_3 data_batch_5 test_batch\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./cifar-10-batches-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = './cifar-10-batches-py/test_batch'\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo,encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "dd = unpickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'labels', b'data', b'filenames', b'batch_label'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = dd[b'data']\n",
    "ydata = dd[b'labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L(X, y, W):\n",
    "    \"\"\"\n",
    "    fully-vectorized implementation :\n",
    "    - X holds all the training examples as columns (e.g. 3073 x 50,000 in CIFAR-10)\n",
    "    - y is array of integers specifying correct class (e.g. 50,000-D array)\n",
    "    - W are weights (e.g. 10 x 3073)\n",
    "    \"\"\"\n",
    "    delta = 1.0\n",
    "    scores = W.dot(X.T)\n",
    "    lidx = range(0, len(y))\n",
    "    margins = np.maximum(0, scores - scores[y, lidx] + delta)\n",
    "    margins[y, lidx] = 0\n",
    "    loss = np.sum(margins)/(len(y))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 164 ms per loop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xdata =[]\n",
    "for x in raw:\n",
    "    xdata.append(np.insert(x,0,1))\n",
    "xdata = np.array(xdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 每个样本增加一个bias 1\n",
    "\n",
    "# 法一\n",
    "# xdata =[]\n",
    "# for x in raw:\n",
    "#     xdata.append(np.insert(x,0,1))\n",
    "# xdata = np.array(xdata)\n",
    "\n",
    "#法二\n",
    "xdata = np.column_stack((raw, np.ones(len(raw))))\n",
    "\n",
    "# 法三\n",
    "# xdata = np.ones((raw.shape[0],raw.shape[1]+1))\n",
    "# xdata[:,:-1] = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 3073), (10000, 3072))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata.shape,raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.081358115448854"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.random.randn(10, 3073) * 0.0001\n",
    "\n",
    "L(xdata,ydata,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = xdata\n",
    "Y_train = ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in attempt 99 the loss was 8.983980, best 8.983980\n"
     ]
    }
   ],
   "source": [
    "# 随机搜索\n",
    "bestloss = float(\"inf\") # Python assigns the highest possible float value\n",
    "for num in range(100):\n",
    "    W = np.random.randn(10, 3073) * 0.0001 # generate random parameters\n",
    "    loss = L(X_train, Y_train, W) # get the loss over the entire training set\n",
    "    if loss < bestloss: # keep track of the best solution\n",
    "        bestloss = loss\n",
    "        bestW = W\n",
    "print('in attempt %d the loss was %f, best %f' % (num, loss, bestloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 loss is 41.519405\n",
      "iter 100 loss is 37.031914\n",
      "iter 200 loss is 32.567393\n",
      "iter 300 loss is 27.555161\n",
      "iter 400 loss is 23.722530\n",
      "iter 500 loss is 21.058190\n",
      "iter 600 loss is 19.341223\n",
      "iter 700 loss is 18.505415\n",
      "iter 800 loss is 17.961653\n",
      "iter 900 loss is 17.513660\n",
      "iter 1000 loss is 17.251243\n"
     ]
    }
   ],
   "source": [
    "#随机下降法\n",
    "W = np.random.randn(10, 3073) * 0.001 # generate random starting W\n",
    "bestloss = float(\"inf\")\n",
    "for i in range(1002):\n",
    "    step_size = 0.00001\n",
    "    Wtry = W + np.random.randn(10, 3073) * step_size\n",
    "    loss = L(X_train, Y_train, Wtry)\n",
    "    if loss < bestloss:\n",
    "        W = Wtry\n",
    "        bestloss = loss\n",
    "    if i%100 == 0:\n",
    "        print('iter %d loss is %f' % (i, bestloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 梯度下降法\n",
    "def eval_numerical_gradient(f, x):\n",
    "    \"\"\" \n",
    "    a naive implementation of numerical gradient of f at x \n",
    "    - f should be a function that takes a single argument\n",
    "    - x is the point (numpy array) to evaluate the gradient at\n",
    "    \"\"\" \n",
    "\n",
    "    fx = f(x) # evaluate function value at original point\n",
    "    grad = np.zeros(x.shape)\n",
    "    h = 0.00001\n",
    "\n",
    "    # iterate over all indexes in x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "\n",
    "        # evaluate function at x+h\n",
    "        ix = it.multi_index\n",
    "        old_value = x[ix]\n",
    "        x[ix] = old_value + h # increment by h\n",
    "        fxh = f(x) # evalute f(x + h)\n",
    "        x[ix] = old_value # restore to previous value (very important!)\n",
    "\n",
    "        # compute the partial derivative\n",
    "        grad[ix] = (fxh - fx) / h # the slope\n",
    "        it.iternext() # step to next dimension\n",
    "\n",
    "    return grad\n",
    "\n",
    "# 10000个太多了,测试1000个\n",
    "k=100\n",
    "def CIFAR10_loss_fun(W):\n",
    "    return L(X_train[:k], Y_train[:k], W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.6 s, sys: 216 ms, total: 18.8 s\n",
      "Wall time: 19.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "W = np.random.rand(10, 3073) * 0.001 # random weight vector\n",
    "\n",
    "df = eval_numerical_gradient(CIFAR10_loss_fun, W) # get the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original loss: 18.754741\n",
      "for step size 0.000000 new loss: 18.740895\n",
      "for step size 0.000000 new loss: 18.616471\n",
      "for step size 0.000000 new loss: 17.402123\n",
      "for step size 0.000000 new loss: 10.438134\n",
      "for step size 0.000001 new loss: 124.150568\n",
      "for step size 0.000010 new loss: 1328.548602\n",
      "for step size 0.000100 new loss: 13372.797059\n",
      "for step size 0.001000 new loss: 133815.281625\n",
      "for step size 0.010000 new loss: 1338240.127288\n",
      "for step size 0.100000 new loss: 13382488.583912\n",
      "CPU times: user 15.1 ms, sys: 2.49 ms, total: 17.6 ms\n",
      "Wall time: 15.2 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "loss_original = CIFAR10_loss_fun(W) # the original loss\n",
    "print('original loss: %f' % (loss_original, ))\n",
    "\n",
    "for step_size_log in [-10, -9, -8, -7, -6, -5,-4,-3,-2,-1]:\n",
    "    step_size = 10 ** step_size_log\n",
    "    W_new = W - step_size * df # new position in the weight space\n",
    "    loss_new = CIFAR10_loss_fun(W_new)\n",
    "    print('for step size %f new loss: %f' % (step_size, loss_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**结论:**要选择大小合适的stepsize\n",
    "\n",
    "- 梯度方向其实是函数增加最快的方向\n",
    "- 梯度下降法是沿着负梯度方向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
